<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=0.7">
    <title>SynthFeel – Synthesizer & Sound Perception</title>
    <link rel="stylesheet" href="css/style.css" />
    <link
      href="https://fonts.googleapis.com/css2?family=Bungee&display=swap"
      rel="stylesheet"
    />
  </head>
  <body class="home-page">
    <div class="menu-toggle">
      <img src="media/image/home.png" alt="Open menu" />
    </div>

    <div class="dropdown-menu">
      <a href="index.html">Home</a>
      <a href="data.html">Data</a>
      <a href="tasks.html">Results</a>
    </div>

    <header class="hero">
      <video autoplay muted loop playsinline id="background-video">
        <source src="media/video/fond.mp4" type="video/mp4" />
      </video>
      <div class="overlay"></div>
      <div class="hero-content">
        <h1>SynthFeel</h1>
        <br />
        <h2>How to create an anxiogenic sound using a virtual synthesizer?</h2>
      </div>
    </header>

    <main class="main-content">
      <section class="centered-section fade-in">
        <h2>Introduction</h2>
        <p>
          The exploration of connections between acoustic parameters and
          emotional perception represents a growing challenge in the fields of
          sound synthesis and music creation assisted by artificial
          intelligence. However, the question of whether certain sound synthesis
          parameters possess an inherently anxiogenic potential has not been
          studied. This study proposes an exploratory analysis conducted from
          sounds generated by a virtual frequency modulation (FM) synthesizer,
          in order to identify characteristics likely to induce a perception of
          anxiety. The variables considered include waveform, temporal dynamics
          (ADSR), internal dissonance, and modulation structure.
        </p>
        <p>
          The objective is twofold: on one hand, to quantify the influence of
          these parameters on the perceived anxiogenic feeling; on the other
          hand, to evaluate the capacity of a statistical model to learn these
          relationships with a view to future applications in perceptive
          modeling and conditioned musical generation.
        </p>
      </section>

      <div class="navigation-buttons fade-in">
        <a href="tasks.html" class="nav-button">See the Results</a>
        <a href="data.html" class="nav-button">Explore the Data</a>
      </div>

      <section class="centered-section fade-in">
        <h2>The Synthesizer: Operator</h2>
        <p>
          The Ableton FM Operator synthesizer consists of four oscillators. Each
          oscillator generates a waveform (sinusoidal, square, triangular,
          sawtooth, etc.) that forms the basis of the sound.
        </p>
        <p>
          In this study, the oscillators were connected according to a
          sequential modulation scheme, where each oscillator (i+1) modulates
          the frequency of the previous one (i), in order to produce more
          complex timbres. Each oscillator has frequency control (perceived
          pitch of the sound) and harmonic variations relative to the frequency
          of the main oscillator. The attack, decay, sustain, and release (ADSR)
          parameters describe the temporal evolution of volume: appearance,
          maintenance, and extinction of the sound.
        </p>
        <img
          src="media/image/imgindex2.jpg"
          alt="Operator Synthesizer"
          class="centered-image"
        />
        <p>
          Filters, envelopes, or effects were not taken into account in order to
          limit complexity and focus the analysis on parameters directly related
          to sound generation.
        </p>
      </section>

      <section class="centered-section fade-in">
        <h2>Methodology</h2>
        <p>
          To construct the dataset of 256 sounds, random generation of
          parameters ensured a more uniform distribution of possible
          combinations. The waveforms of the four oscillators constituted the
          main source of variation, while other parameters — such as modulation
          frequencies (fine) and temporal envelopes (ADSR) — were randomly
          assigned according to representative ranges of slow, medium, or fast
          variations. This method allowed covering a wide range of combinations
          while limiting biases in the distribution of generated sounds.
        </p>
        <p>
          Each sound was implemented in Operator, then evaluated by several
          listeners via an online survey. Since the number of active oscillators
          varied from one sound to another, many parameters were not used,
          resulting in the presence of missing values (NaN) in the dataset. To
          address this problem and maintain a coherent representation of sounds,
          several derived variables were created.
        </p>
      </section>
      <div class="navigation-buttons fade-in">
        <a href="tasks.html" class="nav-button">See the Results</a>
        <a href="data.html" class="nav-button">Explore the Data</a>
      </div>
    </main>

    <footer class="footer">
      <p>&copy; 2025 Synthesizer & Sound Perception — Lélie Chenouga</p>
      <p>
        <a href="index.html">Home</a> | <a href="data.html">Data</a> |
        <a href="tasks.html">Results</a>
      </p>
    </footer>

    <script src="js/common.js"></script>
  </body>
</html>



